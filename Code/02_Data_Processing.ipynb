{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "adlkfnaldf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### External Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import to_inches, impute\n",
    "from os import listdir\n",
    "from fancyimpute import IterativeImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4648, 84)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pga = pd.read_csv('../Data/Sets/full_pga_data.csv')\n",
    "df_pga.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date to datetime\n",
    "df_pga['date'] = pd.to_datetime(df_pga['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a regex filter get a list of distance columns\n",
    "distance_columns = df_pga.filter(\n",
    "    regex = 'distance_from|approaches|proximity|longest_putts|approach_|average_'\n",
    ").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This list of columns will be used in the future for converting features in the form:  ' 20'\\ 6\" '  to total inches as a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## <u> Handle Missing Data <u/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Ignore Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method shrinks the dataset to 3616 observations and 60 features.\n"
     ]
    }
   ],
   "source": [
    "# grab all columns with fewer missing values than 5% of the data\n",
    "drop_rows = []\n",
    "for col in df_pga.columns:\n",
    "    if df_pga[col].isnull().sum() < 0.05 * df_pga.shape[0]:\n",
    "        drop_rows.append(col)\n",
    "        \n",
    "# drop those rows\n",
    "df_pga1 = df_pga.dropna(subset = drop_rows)\n",
    "\n",
    "# create a dataframe with all columns without missing data\n",
    "notnull = []\n",
    "for col in df_pga1.columns:\n",
    "    if df_pga1[col].isnull().sum() == 0:\n",
    "        notnull.append(col)\n",
    "df_notnull = df_pga1[notnull]\n",
    "print(f'This method shrinks the dataset to {df_notnull.shape[0]} \\\n",
    "observations and {df_notnull.shape[1]} features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that by doing this, the number of tournaments shrinks by 1,080 and the number of columns shrinks by 24. However, this smaller dataset contains no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance columns to total inches using to_inches function in functions.py file\n",
    "for col in df_notnull.columns:\n",
    "    if col in distance_columns:\n",
    "        df_notnull[col] = df_notnull[col].apply(lambda x: to_inches(x))\n",
    "        \n",
    "# finish to integer\n",
    "df_notnull['finish'] = df_notnull['finish'].apply(lambda x: x.strip('T')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notnull.to_csv('../Data/Sets/model_one.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Method 2: Hot-Deck Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method shrinks the number of features to 69 but keeps the 4648 observations.\n"
     ]
    }
   ],
   "source": [
    "# get a list of columns with more than 500 missing values and drop them\n",
    "drop_cols = []\n",
    "for col in df_pga.columns:\n",
    "    if df_pga[col].isnull().sum() > 500:\n",
    "        drop_cols.append(col)\n",
    "df_pga2 = df_pga.drop(columns = drop_cols)\n",
    "print(f'This method shrinks the number of features to {df_pga2.shape[1]} \\\n",
    "but keeps the {df_pga2.shape[0]} observations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This process gets rid of 15 columns that contain enough missing values to argue that those statistics will not influence golf performance. A large majority of these columns are approaches from the rough and approach shots from an unordinary distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance columns to total inches\n",
    "for col in df_pga2.columns:\n",
    "    if col in distance_columns:\n",
    "        df_pga2[col] = df_pga2[col].apply(lambda x: to_inches(x))\n",
    "        \n",
    "# finish to integer\n",
    "df_pga2['finish'] = df_pga2['finish'].apply(lambda x: x.strip('T')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of players again from directory\n",
    "players = listdir('../Data/')\n",
    "\n",
    "# remove unwanted files/folders\n",
    "players.remove('.DS_Store') \n",
    "players.remove('.ipynb_checkpoints')\n",
    "players.remove('Sets')\n",
    "len(players)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each column that contains missing values. Replace the missing \n",
    "# values with a random choice from each players distribution of that feature.\n",
    "for col in df_pga2.columns:\n",
    "    if df_pga2[col].isnull().sum() > 0:  \n",
    "        new_vals = []\n",
    "        for player in players:\n",
    "            filled = impute(df_pga2, col, player)\n",
    "            new_vals.extend(filled)\n",
    "        df_pga2[col] = new_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hot-Deck imputation fills a missing value by choosing a random value from a the list of observed values for the corresponding player and feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pga2.to_csv('../Data/Sets/model_two.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Method 3: Regression Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 3 takes four steps:\n",
    "- Step 1: Drop columns with too many missing values to add any significance.\n",
    "- Step 2: Drop rows with missing values in columns that rarely have missing values.\n",
    "- Step 3: Created binary encoded columns for columns that contain missing values:\n",
    "    - 1 means the value is missing.\n",
    "    - 0 means the value is not missing.\n",
    "- Step 4: Use IterativeImputer to fill missing values with a prediction calculated by a regression using observed values for each tournament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop the same 15 columns as in method 2.\n"
     ]
    }
   ],
   "source": [
    "# drop columns with overwhelming missing values\n",
    "drop_cols = []\n",
    "for col in df_pga.columns:\n",
    "    if df_pga[col].isnull().sum() > 500:\n",
    "        drop_cols.append(col)\n",
    "df_pga3 = df_pga.drop(columns = drop_cols)\n",
    "print('Drop the same 15 columns as in method 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drops 110 rows.\n"
     ]
    }
   ],
   "source": [
    "# grab all columns with fewer missing values than 5% of the data\n",
    "drop_rows = []\n",
    "for col in df_pga3.columns:\n",
    "    if df_pga3[col].isnull().sum() < 25:\n",
    "        drop_rows.append(col)\n",
    "        \n",
    "# drop rows with missing data in those columns\n",
    "df_pga3.dropna(subset = drop_rows, inplace = True)\n",
    "print('Drops 110 rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping these 110 rows significantly reduces the number of columns with missing data. It makes the encoding step much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance columns to total inches\n",
    "for col in df_pga3.columns:\n",
    "    if col in distance_columns:\n",
    "        df_pga3[col] = df_pga3[col].apply(lambda x: to_inches(x))\n",
    "        \n",
    "# finish to integer\n",
    "df_pga3['finish'] = df_pga3['finish'].apply(lambda x: x.strip('T')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add 22 news encoded columns for remaining columns that contain missing valus.\n"
     ]
    }
   ],
   "source": [
    "# create an encoded column containing a 1 \n",
    "# if the value is missing and a 0 if it is not\n",
    "encode_list = []\n",
    "for col in df_pga3.columns:\n",
    "    if 25 < df_pga3[col].isnull().sum() < 500:\n",
    "        encode_list.append(col)\n",
    "        \n",
    "for col in encode_list:\n",
    "    df_pga3[f'{col}_encoded'] = df_pga3[col].map(lambda x: 1 if np.isnan(x) else 0)\n",
    "print('Add 22 news encoded columns for remaining columns that contain missing valus.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating these binary columns serves to add information about missing values to the model. If the value was missing, the coefficient on the encoded column will account for the missingness. If it is not missing, it does not affect the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only numeric columns to prepare for imputation\n",
    "num_cols = [col for col in df_pga3.columns if col not in ['date', 'player', 'event']]\n",
    "df_pga3 = df_pga3[num_cols]\n",
    "\n",
    "# Use IterativeImputer to fill missing values. \n",
    "# This library fills the missing values with a prediction calculated\n",
    "# from a regression based on other observed values\n",
    "myimputer = IterativeImputer()\n",
    "df_pga3_transformed = myimputer.fit_transform(df_pga3)\n",
    "df_filled = pd.DataFrame(df_pga3_transformed)  \n",
    "\n",
    "# rename the columns\n",
    "df_filled.columns = df_pga3.columns\n",
    "\n",
    "# add the non-numeric columns\n",
    "df_filled[['date', 'player', 'event']] = df_pga[['date', 'player', 'event']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to csv for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.to_csv('../Data/Sets/model_three.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
