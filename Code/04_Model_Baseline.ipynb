{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Model Baseline\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The main goal of this notebook is determine which of the three methods for handling missing values is most appropriate for the data. To achieve this, a basic linear regression is fit to each unique set of data and then compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### External Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Cleaned Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from method 1\n",
    "df_pga1 = pd.read_csv('../Data/Sets/model_one.csv')\n",
    "# from method 2\n",
    "df_pga2 = pd.read_csv('../Data/Sets/model_two.csv')\n",
    "# from method 3\n",
    "df_pga3 = pd.read_csv('../Data/Sets/model_three.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## <u>Preparation for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features, remove irrelevant columns and strokes gained columns\n",
    "features = [\n",
    "    col for col in df_pga1.columns if col not in ['date', 'finish', \n",
    "                                                  'player', 'event', \n",
    "                                                  'sg:_off-the-tee',\n",
    "                                                  'sg:_approach-the-green',\n",
    "                                                  'sg:_around-the-green',\n",
    "                                                  'sg:_putting',\n",
    "                                                  'sg:_total']]\n",
    "\n",
    "# choose X and y variables\n",
    "X1 = df_pga1[features]\n",
    "y1 = df_pga1['sg:_total']\n",
    "\n",
    "# train, test split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, \n",
    "                                                        test_size = 0.3, random_state = 77)\n",
    "# scale the data (subtract mean and divide by standard deviation)\n",
    "ss = StandardScaler()\n",
    "X_train1_sc = ss.fit_transform(X_train1)\n",
    "X_test1_sc = ss.transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features, remove irrelevant columns and strokes gained columns\n",
    "features = [\n",
    "    col for col in df_pga2.columns if col not in ['date', 'finish', \n",
    "                                                  'player', 'event', \n",
    "                                                  'sg:_off-the-tee',\n",
    "                                                  'sg:_approach-the-green',\n",
    "                                                  'sg:_around-the-green',\n",
    "                                                  'sg:_putting',\n",
    "                                                  'sg:_total']]\n",
    "\n",
    "X2 = df_pga2[features]\n",
    "y2 = df_pga2['sg:_total']\n",
    "\n",
    "# train, test split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, \n",
    "                                                        test_size = 0.3, random_state = 77)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train2_sc = ss.fit_transform(X_train2)\n",
    "X_test2_sc = ss.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features, remove irrelevant columns and strokes gained columns\n",
    "features = [\n",
    "    col for col in df_pga3.columns if col not in ['date', 'finish', \n",
    "                                                  'player', 'event', \n",
    "                                                  'sg:_off-the-tee',\n",
    "                                                  'sg:_approach-the-green',\n",
    "                                                  'sg:_around-the-green',\n",
    "                                                  'sg:_putting',\n",
    "                                                  'sg:_total']]\n",
    "\n",
    "X3 = df_pga3[features]\n",
    "y3 = df_pga3['sg:_total']\n",
    "\n",
    "# train, test split\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, \n",
    "                                                        test_size = 0.3, random_state = 77)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train3_sc = ss.fit_transform(X_train3)\n",
    "X_test3_sc = ss.transform(X_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Comparing Models\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 produces an average R-squared of 0.5894856748890387.\n",
      "Model 2 produces an average R-squared of 0.5679173216443035.\n",
      "Model 3 produces an average R-squared of 0.5672825566325466.\n"
     ]
    }
   ],
   "source": [
    "# instantiate basic linear regression model\n",
    "lr = LinearRegression()\n",
    "# instantiate a KFold to shuffle the data on every cross fold\n",
    "kf = KFold(n_splits = 10 , shuffle = True , random_state = 77)\n",
    "\n",
    "# fit a model for each of the three models\n",
    "lr1_cv = cross_val_score(lr, X_train1_sc, y_train1, cv=kf).mean()\n",
    "lr2_cv = cross_val_score(lr, X_train2_sc, y_train2, cv=kf).mean()\n",
    "lr3_cv = cross_val_score(lr, X_train3_sc, y_train3, cv=kf).mean()\n",
    "\n",
    "print(f'Model 1 produces an average R-squared of {lr1_cv}.')\n",
    "print(f'Model 2 produces an average R-squared of {lr2_cv}.')\n",
    "print(f'Model 3 produces an average R-squared of {lr3_cv}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1 produces the highest R-squared score on the training data. The model explains 58.89% more of the variability in the data compared to the mean of Strokes Gained: Total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 produces an R-squared score of 0.60282 on unseen data.\n",
      "Model 2 produces an R-squared score of 0.55097 on unseen data.\n",
      "Model 3 produces an R-squared score of 0.56553 on unseen data.\n"
     ]
    }
   ],
   "source": [
    "# instantiate three models\n",
    "lr1 = LinearRegression()\n",
    "lr2 = LinearRegression()\n",
    "lr3 = LinearRegression()\n",
    "\n",
    "# fit the three sets of data to their own model\n",
    "lr1.fit(X_train1_sc, y_train1)\n",
    "lr2.fit(X_train2_sc, y_train2)\n",
    "lr3.fit(X_train3_sc, y_train3)\n",
    "\n",
    "print(f'Model 1 produces an R-squared score \\\n",
    "of {round(lr1.score(X_test1_sc, y_test1), 5)} on unseen data.')\n",
    "\n",
    "print(f'Model 2 produces an R-squared score \\\n",
    "of {round(lr2.score(X_test2_sc, y_test2), 5)} on unseen data.')\n",
    "\n",
    "print(f'Model 3 produces an R-squared score \\\n",
    "of {round(lr3.score(X_test3_sc, y_test3), 5)} on unseen data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "- Remember that the only difference between the three models is the data being used as input. The data for each model is different based on the methods used in the second notebook for handling the missing values.\n",
    "- A score of 0.60282 for the testing data means that the model explains 60.282% of variation in Total Strokes Gained compared to the mean's ability to predict Total Strokes Gained. In the unpredictable game of golf, this score is enough for significant interpretation.\n",
    "- When comparing each model, Model 1 explains nearly 4% more variation in Strokes Gained than the other models. While this difference is not drastic, it suggests the lack of importance of the missing data in the modeling process.\n",
    "- For Model 1, the missing data was removed and ignored. This method lends to the simplicity and interpretability of the model. Because of this, Model 1 will be further tuned and carried into the regression analysis of Club Head Speed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
